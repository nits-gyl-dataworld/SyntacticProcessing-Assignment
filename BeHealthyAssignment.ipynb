{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e62328ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycrf in ./python/anaconda3/lib/python3.11/site-packages (0.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pycrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3145e5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-crfsuite in ./python/anaconda3/lib/python3.11/site-packages (0.3.6)\r\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in ./python/anaconda3/lib/python3.11/site-packages (from sklearn-crfsuite) (0.9.10)\r\n",
      "Requirement already satisfied: six in ./python/anaconda3/lib/python3.11/site-packages (from sklearn-crfsuite) (1.16.0)\r\n",
      "Requirement already satisfied: tabulate in ./python/anaconda3/lib/python3.11/site-packages (from sklearn-crfsuite) (0.8.10)\r\n",
      "Requirement already satisfied: tqdm>=2.0 in ./python/anaconda3/lib/python3.11/site-packages (from sklearn-crfsuite) (4.65.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-crfsuite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6b65f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in ./python/anaconda3/lib/python3.11/site-packages (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./python/anaconda3/lib/python3.11/site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: language-data>=1.2 in ./python/anaconda3/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./python/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in ./python/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./python/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./python/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./python/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./python/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./python/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./python/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./python/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./python/anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in ./python/anaconda3/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./python/anaconda3/lib/python3.11/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in ./python/anaconda3/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36684e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import model and metrics\n",
    "from sklearn_crfsuite import CRF, scorers, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59589f7",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05cf791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ae5dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_extract(file_path='',sep='\\t'):\n",
    "    ''' extract the word based on the separator to form the sentence'''\n",
    "    try:\n",
    "        with open (file_path,'r',encoding='utf-8') as text:\n",
    "            if text.mode  == 'r':\n",
    "                content = text.readlines()\n",
    "        sentence = []\n",
    "        final_sentence=''\n",
    "        for c in content:\n",
    "            content_word = c.strip('\\n')\n",
    "            if content_word == '':\n",
    "                #Once it get matched with separator, it appends previous extracted concatenated string as sentence\n",
    "#                 final_sentence = re.sub('(?<=[\\(]) | (?=[%\\',)])','', final_sentence)\n",
    "                sentence.append(final_sentence.strip(' '))\n",
    "\n",
    "                #Initialize for next sentence\n",
    "                final_sentence=''\n",
    "            else:\n",
    "                # Till the loop identifies the separator it concatenates string\n",
    "                final_sentence+=content_word+' '\n",
    "        print('Total identified value: ',len(sentence),'\\n')\n",
    "        print('Sample display value:\\n',sentence[:5])\n",
    "        return sentence\n",
    "    except FileNotFoundError:\n",
    "        print('Check and provide proper file path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e12d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Post-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1a6190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to retrieve the sentences details from the dataframe\n",
    "class sentencedetail(object):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, l) for w, p, l in zip(s[\"word\"].values.tolist(), s[\"pos\"].values.tolist(),s[\"label\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"sentence\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c39a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1363713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature set\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[0]': word[0],\n",
    "        'word[-1]': word[-1],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag':postag,\n",
    "        'postag_isnounpronoun': postag in ['NOUN','PROPN'],\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word[0]': word1[0],\n",
    "            '-1:word[-1]': word1[-1],\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "            '-1:postag_isnounpronoun': postag1 in ['NOUN','PROPN']\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "            '+1:postag_isnounpronoun': postag1 in ['NOUN','PROPN']\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dedd8770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract features for a sentence.\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffc36d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96a182d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total identified value:  2599 \n",
      "\n",
      "Sample display value:\n",
      " ['O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O']\n"
     ]
    }
   ],
   "source": [
    "# Train label extraction from dataset\n",
    "train_label = content_extract(file_path='/Users/nishitgoyal/Documents/Personal Docs/Data Sceince/NLP/train_label',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d43286e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total identified value:  2599 \n",
      "\n",
      "Sample display value:\n",
      " ['All live births > or = 23 weeks at the University of Vermont in 1995 ( n = 2395 ) were retrospectively analyzed for delivery route , indication for cesarean , gestational age , parity , and practice group ( to reflect risk status )', 'The total cesarean rate was 14.4 % ( 344 of 2395 ) , and the primary rate was 11.4 % ( 244 of 2144 )', 'Abnormal presentation was the most common indication ( 25.6 % , 88 of 344 )', \"The `` corrected '' cesarean rate ( maternal-fetal medicine and transported patients excluded ) was 12.4 % ( 273 of 2194 ) , and the `` corrected '' primary rate was 9.6 % ( 190 of 1975 )\", \"Arrest of dilation was the most common indication in both `` corrected '' subgroups ( 23.4 and 24.6 % , respectively )\"]\n"
     ]
    }
   ],
   "source": [
    "# Train sentence extraction from dataset\n",
    "train_sent = content_extract(file_path='/Users/nishitgoyal/Documents/Personal Docs/Data Sceince/NLP/train_sent',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44f46c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total identified value:  1056 \n",
      "\n",
      "Sample display value:\n",
      " ['Furthermore , when all deliveries were analyzed , regardless of risk status but limited to gestational age > or = 36 weeks , the rates did not change ( 12.6 % , 280 of 2214 ; primary 9.2 % , 183 of 1994 )', 'As the ambient temperature increases , there is an increase in insensible fluid loss and the potential for dehydration', 'The daily high temperature ranged from 71 to 104 degrees F and AFI values ranged from 1.7 to 24.7 cm during the study period', 'There was a significant correlation between the 2- , 3- , and 4-day mean temperature and AFI , with the 4-day mean being the most significant ( r = 0.31 , p & # 60 ; 0.001 )', 'Fluctuations in ambient temperature are inversely correlated to changes in AFI']\n"
     ]
    }
   ],
   "source": [
    "# Test sentence extraction from dataset\n",
    "test_sent = content_extract(file_path='/Users/nishitgoyal/Documents/Personal Docs/Data Sceince/NLP/test_sent',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48bd0104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total identified value:  1056 \n",
      "\n",
      "Sample display value:\n",
      " ['O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O']\n"
     ]
    }
   ],
   "source": [
    "# Test label extraction from dataset\n",
    "test_label = content_extract(file_path='/Users/nishitgoyal/Documents/Personal Docs/Data Sceince/NLP/test_label',sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b4ace4",
   "metadata": {},
   "source": [
    "# # Extract POS Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb9ac843",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp= spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29656c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.DataFrame(columns=['sentence','word','lemma','pos','label'])\n",
    "test_df = pd.DataFrame(columns=['sentence','word','lemma','pos','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c938f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train datframe\n",
    "\n",
    "i=0 #Sentence count\n",
    "j=0 #Iteration count\n",
    "\n",
    "for sent,label in zip(train_sent,train_label):\n",
    "    i+=1\n",
    "    for s,l in zip(sent.split(),label.split()):\n",
    "        doc = nlp(s)\n",
    "        for tok in doc:\n",
    "            train_df.loc[j,['sentence','word','lemma','pos','label']] = [i,tok.text,tok.lemma_,tok.pos_,l]\n",
    "            j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d3a0871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test datframe\n",
    "\n",
    "i=0 #Sentence count\n",
    "j=0 #Iteration count\n",
    "\n",
    "for sent,label in zip(test_sent,test_label):\n",
    "    i+=1\n",
    "    for s,l in zip(sent.split(),label.split()):\n",
    "        doc = nlp(s)\n",
    "        for tok in doc:\n",
    "            test_df.loc[j,['sentence','word','lemma','pos','label']] = [i,tok.text,tok.lemma_,tok.pos_,l]\n",
    "            j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b04b7214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word and it's frequency for word which contains NOUN or PROPN as POS tagging\n",
    "freq_df = pd.DataFrame()\n",
    "freq_df = pd.concat((train_df,test_df),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a885ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting index\n",
    "freq_df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42f7875b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOUN     19770\n",
       "ADP       8655\n",
       "VERB      7457\n",
       "PUNCT     6576\n",
       "ADJ       6208\n",
       "PRON      5406\n",
       "PROPN     3243\n",
       "CCONJ     2352\n",
       "NUM       2304\n",
       "AUX       1925\n",
       "ADV       1770\n",
       "PART      1042\n",
       "INTJ       437\n",
       "SYM        284\n",
       "X          236\n",
       "SCONJ      231\n",
       "DET         11\n",
       "Name: pos, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_df['pos'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8e90cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patients        492\n",
       "treatment       281\n",
       "cancer          200\n",
       "therapy         175\n",
       "disease         143\n",
       "cell            140\n",
       "lung            116\n",
       "group            94\n",
       "gene             88\n",
       "chemotherapy     88\n",
       "effects          85\n",
       "results          79\n",
       "women            77\n",
       "patient          75\n",
       "TO_SEE           75\n",
       "surgery          71\n",
       "risk             71\n",
       "cases            71\n",
       "analysis         70\n",
       "human            67\n",
       "rate             67\n",
       "response         66\n",
       "survival         65\n",
       "children         64\n",
       "effect           64\n",
       "Name: word, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_df[(freq_df['pos'] == 'NOUN') | ((freq_df['pos'] == 'PROPN'))]['word'].value_counts()[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30601b9d",
   "metadata": {},
   "source": [
    "Dataframe (Sentence, word, POS) visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77e7b365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>All</td>\n",
       "      <td>all</td>\n",
       "      <td>PRON</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>live</td>\n",
       "      <td>live</td>\n",
       "      <td>VERB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>births</td>\n",
       "      <td>birth</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>&gt;</td>\n",
       "      <td>&gt;</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>or</td>\n",
       "      <td>or</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence    word  lemma    pos label\n",
       "0        1     All    all   PRON     O\n",
       "1        1    live   live   VERB     O\n",
       "2        1  births  birth   NOUN     O\n",
       "3        1       >      >  PUNCT     O\n",
       "4        1      or     or  CCONJ     O"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb707a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sentense-wise detail dataframe preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95f8e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch detail view of sentence for train set\n",
    "train_sent_obj = sentencedetail(train_df)\n",
    "train_sent_detail = train_sent_obj.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be75b6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('All', 'PRON', 'O'),\n",
       " ('live', 'VERB', 'O'),\n",
       " ('births', 'NOUN', 'O'),\n",
       " ('>', 'PUNCT', 'O'),\n",
       " ('or', 'CCONJ', 'O'),\n",
       " ('=', 'VERB', 'O'),\n",
       " ('23', 'NUM', 'O'),\n",
       " ('weeks', 'NOUN', 'O'),\n",
       " ('at', 'ADP', 'O'),\n",
       " ('the', 'PRON', 'O'),\n",
       " ('University', 'NOUN', 'O'),\n",
       " ('of', 'ADP', 'O'),\n",
       " ('Vermont', 'PROPN', 'O'),\n",
       " ('in', 'ADP', 'O'),\n",
       " ('1995', 'NUM', 'O'),\n",
       " ('(', 'PUNCT', 'O'),\n",
       " ('n', 'CCONJ', 'O'),\n",
       " ('=', 'VERB', 'O'),\n",
       " ('2395', 'NUM', 'O'),\n",
       " (')', 'PUNCT', 'O'),\n",
       " ('were', 'AUX', 'O'),\n",
       " ('retrospectively', 'ADV', 'O'),\n",
       " ('analyzed', 'VERB', 'O'),\n",
       " ('for', 'ADP', 'O'),\n",
       " ('delivery', 'NOUN', 'O'),\n",
       " ('route', 'NOUN', 'O'),\n",
       " (',', 'PUNCT', 'O'),\n",
       " ('indication', 'NOUN', 'O'),\n",
       " ('for', 'ADP', 'O'),\n",
       " ('cesarean', 'VERB', 'O'),\n",
       " (',', 'PUNCT', 'O'),\n",
       " ('gestational', 'ADJ', 'O'),\n",
       " ('age', 'NOUN', 'O'),\n",
       " (',', 'PUNCT', 'O'),\n",
       " ('parity', 'NOUN', 'O'),\n",
       " (',', 'PUNCT', 'O'),\n",
       " ('and', 'CCONJ', 'O'),\n",
       " ('practice', 'VERB', 'O'),\n",
       " ('group', 'NOUN', 'O'),\n",
       " ('(', 'PUNCT', 'O'),\n",
       " ('to', 'PART', 'O'),\n",
       " ('reflect', 'VERB', 'O'),\n",
       " ('risk', 'NOUN', 'O'),\n",
       " ('status', 'NOUN', 'O'),\n",
       " (')', 'PUNCT', 'O')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display one sentence detail view for train set\n",
    "train_sent_detail[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8cd200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch detail view of sentence for test set\n",
    "test_sent_obj = sentencedetail(test_df)\n",
    "test_sent_detail = test_sent_obj.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87726921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Furthermore', 'ADV', 'O'),\n",
       " (',', 'PUNCT', 'O'),\n",
       " ('when', 'SCONJ', 'O'),\n",
       " ('all', 'PRON', 'O'),\n",
       " ('deliveries', 'NOUN', 'O'),\n",
       " ('were', 'AUX', 'O'),\n",
       " ('analyzed', 'VERB', 'O'),\n",
       " (',', 'PUNCT', 'O'),\n",
       " ('regardless', 'ADV', 'O'),\n",
       " ('of', 'ADP', 'O'),\n",
       " ('risk', 'NOUN', 'O'),\n",
       " ('status', 'NOUN', 'O'),\n",
       " ('but', 'CCONJ', 'O'),\n",
       " ('limited', 'VERB', 'O'),\n",
       " ('to', 'PART', 'O'),\n",
       " ('gestational', 'ADJ', 'O'),\n",
       " ('age', 'NOUN', 'O'),\n",
       " ('>', 'PUNCT', 'O'),\n",
       " ('or', 'CCONJ', 'O'),\n",
       " ('=', 'VERB', 'O'),\n",
       " ('36', 'NUM', 'O'),\n",
       " ('weeks', 'NOUN', 'O'),\n",
       " (',', 'PUNCT', 'O'),\n",
       " ('the', 'PRON', 'O'),\n",
       " ('rates', 'NOUN', 'O'),\n",
       " ('did', 'VERB', 'O'),\n",
       " ('not', 'PART', 'O'),\n",
       " ('change', 'VERB', 'O'),\n",
       " ('(', 'PUNCT', 'O'),\n",
       " ('12.6', 'NUM', 'O'),\n",
       " ('%', 'INTJ', 'O'),\n",
       " (',', 'PUNCT', 'O'),\n",
       " ('280', 'NUM', 'O'),\n",
       " ('of', 'ADP', 'O'),\n",
       " ('2214', 'NUM', 'O'),\n",
       " (';', 'PUNCT', 'O'),\n",
       " ('primary', 'NOUN', 'O'),\n",
       " ('9.2', 'NUM', 'O'),\n",
       " ('%', 'INTJ', 'O'),\n",
       " (',', 'PUNCT', 'O'),\n",
       " ('183', 'NUM', 'O'),\n",
       " ('of', 'ADP', 'O'),\n",
       " ('1994', 'NUM', 'O'),\n",
       " (')', 'PUNCT', 'O')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display one sentence detail view for test set\n",
    "test_sent_detail[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "844773b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and Target Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e49c369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X-train and X-test by extracting features from train and test dataset\n",
    "X_train = [sent2features(s) for s in train_sent_detail]\n",
    "X_test = [sent2features(s) for s in test_sent_detail]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "871d9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare y-train and y-test by extracting labels from train and test dataset\n",
    "y_train = [sent2labels(l) for l in train_sent_detail]\n",
    "y_test = [sent2labels(l) for l in test_sent_detail]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "660320bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building CRF model using sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3928eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CRF model.\n",
    "try:\n",
    "    crf = CRF(max_iterations=100, c1=1.0, c2=0.01, all_possible_transitions=False)\n",
    "\n",
    "    # fit the model\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError as e:\n",
    "    print(f\"AttributeError occurred: {e}\")\n",
    "    # Handle the AttributeError here, such as providing a default behavior or logging the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d40f5389",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate model (F1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c855fc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted F1-score for Medical Entity Dataset is: 91.47 % \n"
     ]
    }
   ],
   "source": [
    "# Calculate the f1 score using the test data\n",
    "y_pred = crf.predict(X_test)\n",
    "f1_score = metrics.flat_f1_score(y_test, y_pred, average='weighted')\n",
    "print('Predicted F1-score for Medical Entity Dataset is: {0} % '.format(round(f1_score*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10c29b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict Disease and Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3edb926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken out predicted label from the model\n",
    "pred_label=[]\n",
    "for i in y_pred:\n",
    "    pred_label.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bf2bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded into test dataframe\n",
    "test_df['label_predicted'] = pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9992bdfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>label</th>\n",
       "      <th>label_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Furthermore</td>\n",
       "      <td>furthermore</td>\n",
       "      <td>ADV</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>when</td>\n",
       "      <td>when</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>PRON</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>deliveries</td>\n",
       "      <td>delivery</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence         word        lemma    pos label label_predicted\n",
       "0        1  Furthermore  furthermore    ADV     O               O\n",
       "1        1            ,            ,  PUNCT     O               O\n",
       "2        1         when         when  SCONJ     O               O\n",
       "3        1          all          all   PRON     O               O\n",
       "4        1   deliveries     delivery   NOUN     O               O"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualise top 5 data\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e96383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dictionary Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6d12502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing dictionary by keeping Disease as unique Key element and Treatment as value element\n",
    "new_df =test_df[(test_df['label_predicted'] != 'O')]\n",
    "new_df.set_index('sentence',inplace=True)\n",
    "disease=[]\n",
    "treatment=[]\n",
    "sentence=[]\n",
    "med_dict = {}\n",
    "for i in new_df.index.unique():\n",
    "    try:\n",
    "        val = new_df.loc[i,'label_predicted'].unique()\n",
    "        if len(val) == 2:\n",
    "            disease_val = new_df[new_df['label_predicted'] == 'D'].loc[i,'word']\n",
    "            treatment_val = new_df[new_df['label_predicted'] == 'T'].loc[i,'word']\n",
    "            disease_single = disease_val if type(disease_val) == str else \" \".join(disease_val)\n",
    "            treatment_single = treatment_val if type(treatment_val) == str else \" \".join(treatment_val)\n",
    "            if disease_single not in disease:\n",
    "                med_dict[disease_single] = treatment_single\n",
    "            else:\n",
    "                print('Entered')\n",
    "                med_dict[disease_single] = med_dict.get(disease_single)+'/'+treatment_single\n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "79218876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gestational diabetes cases': 'good glycemic control', 'nonimmune hydrops fetalis': 'Trisomy', 'retinoblastoma': 'radiotherapy', 'epilepsy': 'Methylphenidate', 'unstable angina or non - Q - wave myocardial infarction': 'roxithromycin', 'coronary - artery disease': 'Antichlamydial antibiotics', 'primary pulmonary hypertension ( PPH )': 'fenfluramines', 'foot infection': 'G - CSF treatment', 'hemorrhagic stroke': 'double - bolus alteplase alteplase ( P=0.24', 'cardiac disease': 'fenfluramine - phentermine', 'rheumatoid arthritis': 'arthrodesis', \"early Parkinson 's disease\": 'Ropinirole monotherapy', 'sore throat': 'Antibiotics', 'female stress urinary incontinence': 'surgical treatment', 'corpal gastritis': 'gastric acid secretion', 'preeclampsia ( proteinuric hypertension )': 'intrauterine insemination with donor sperm intrauterine insemination', 'severe acquired hyperammonemia cancer': 'organ transplantation and chemotherapy', 'major pulmonary embolism': 'thrombolytic treatment', 'malignant pleural mesothelioma': 'thoracotomy , radiotherapy , and chemotherapy', 'non - obstructive azoospermia': 'TEFNA', 'testicular bleeding': 'fine needle aspiration', 'heart failure': 'beta - blockade', 'duodenal ulcer': 'subtotal gastrectomy', 'colorectal cancer': 'docosahexanoic acid ( DHA ) -concentrated fish oil capsules', 'gastrointestinal tumours': 'Elective surgery', 'bronchial asthma': 'Non - steroidal anti - inflammatory therapy', \"'s disease\": 'Ovine Johne', \"Parkinson 's disease\": 'Microelectrode - guided posteroventral pallidotomy', 'Alopecia': 'tacrolimus therapy', \"Eisenmenger 's syndrome\": 'laparoscopic cholecystectomy', 'breast cancer': 'Hormone replacement therapy', 'non - seminomatous germ - cell tumors': 'chemotherapy', 'orthotopic tumor control': 'adenovirus - mediated interleukin 12 ( il-12 ) gene therapy', 'malignant tumors such as non - small cell lung cancer': 'surgery', 'inflammatory skin diseases': 'topical corticosteroids', 'nsclc nsclc ( stage iiib ) sclc': 'got surgical treatment chemo- and radiotherapy', 'nsclc': 'sequential chemotherapy', 'locally advanced non - small - cell lung cancer ( la - nsclc )': 'combined - modality therapy ( cmt ; chemotherapy and radiotherapy )', 'radiation - induced myelopathy': 'heparin and enoxaparin', 'limited stage small cell lung cancer': 'vip combination chemotherapy and early concurrent thoracic irradiation', 'regionally advanced disease': 'resection , allowing neoadjuvant therapy', 'malignant pleural effusions from nsclc': 'systemic chemotherapy', 'small - cell lung cancer': 'combination chemotherapy', 'intraluminal early - stage cancer': 'photodynamic therapy , nd - yag laser and electrocautery', 'supraclavicular node metastases in nsclc': 'chemoradiotherapy', 'non - small - cell - lung - cancer ( nsclc ) patients': 'cisplatin and radiotherapy', 'lung carcinoma': 'videothoracoscopic lobectomy or partial resection of the lung instead of an open thoracotomy', 'stage 0 lung carcinoma': 'curative therapy', 'single non - sclc ovarian carcinoma brain metastasis': 'surgical resection', 'colorectal metastases': 'therapeutic vats metastasectomy', 'limited - stage small - cell carcinoma of the lung': 'combined - modality therapy', 'advanced nsclc': 'assessing combination chemotherapy of cisplatin , ifosfamide and irinotecan with rhg - csf support', 'metastatic colorectal cancer': 'other agents', \"non - hodgkin 's lymphoma breast cancer mesothelioma and non - small cell lung cancer\": 'oxaliplatin', 'primary tumor ( li ) bronchogenic carcinoma': 'resection', 'non - small cell lung cancer hormone refractory prostate cancer': 'paclitaxel and carboplatin', 'primary lung cancer adenocarcinoma squamous cell carcinoma ( sq )': 'resection', 'stage iii nsclc': 'chemotherapy administered before surgery or definitive irradiation', 'advanced non -- small - cell lung cancer': 'paclitaxel plus carboplatin ( pc ) vinorelbine plus cisplatin ( vc )', 'sclc extensive disease': 'platinum dose ( cisplatin plus carboplatin ) in combination chemotherapy combination therapy with carboplatin', 'untreated small cell lung cancer ( sclc ) untreated sclc': 'technetium-99 m tetrofosmin ( tc - tf ) accumulation chemotherapy', 'head and neck cancer': 'irradiation therapy intravenous amifostine', 'psoriasis': 'topical therapy', 'third nerve palsy': 'lateral rectus surgery sixth nerve palsy', 'disseminated malignant melanoma': 'leukocyte A recombinant interferon ( rIFN - alpha A , Roferon - A', 'advanced stage ( TNM IIB - IVB ) mycosis fungoides': 'combination chemotherapy program consisting of bleomycin and methotrexate weekly', 'ventricular tachycardia': 'surgical therapy', 'non - functioning endocrine pancreatic tumor': 'i.m . lanreotide therapy', 'cholestasis': 'crude drugs', 'severe acute hepatitis accompanying cholestasis autoimmune hepatitis': 'TJ-135', 'syringomyelia spinal adhesive arachnoiditis': 'Surgical management', 'symptomatic bronchiectasis': 'antibiotics , antibronchoobstructive medication , and chest physical therapy', 'bronchiectasis': 'Current surgical therapy', 'biliary colic symptoms biliary dyskinesia': 'cholecystectomy', 'biliary dyskinesia': 'Cholecystectomy', 'common cold': 'Macrolide antibiotics', 'inflammation': 'video - assisted thoracoscopic surgery', 'asthma': 'Fluticasone propionate', 'acute nasopharyngitis': 'antibiotic treatment', 'infection': 'antileukemic therapy', 'influenza breast cancer': 'vaccination', 'carcinoma': 'esophagectomy', 'persistent asthma': 'Contemporary asthma management guidelines list inhaled corticosteroids', 'chronic hepatitis C': 'Combination therapy with interferon - alpha ( IFN alpha ) plus Ribavirin', 'hepatitis C viremia': 'combination therapy', 'duodenogastric reflux': 'cholecystectomy', 'severe hypoxemia': 'glucocorticoid pulse therapy', 'AOM': 'Amoxicillin remains the antibiotic of choice', 'bacterial meningitis include a dramatic decline Haemophilus influenzae meningitis': 'antibiotic - resistant strains', 'acute myocardial infarction': 'thrombolytic treatment', 'ischemic heart disease': 'Aortocoronary bypass grafting', 's.c . tumors peritoneal tumors': 'Subcutaneous injection of irradiated LLC - IL2 did', 'stenosis': 'thrombolytic therapy', 'inflammatory and autoimmune diseases': 'High - dose intravenous immunoglobulin ( hdIVIg )', 'cancer': 'Matrix metalloproteinase inhibitors', 'phaeochromocytoma': 'Adrenalectomy', 'malignant melanoma': 'single agent therapy interferon alfa-2a', 'advanced renal cell carcinoma': 'interferon alfa - N1 , interferon alfa-2a , and interferon alfa-2b', \"low - grade non - Hodgkin 's lymphoma\": 'interferon alpha', 'partial seizures': 'lamotrigine monotherapy', 'esophageal achalasia': 'botulinum toxin injection , pneumatic dilation , and laparoscopic myotomy', 'irritable bowel syndrome': 'Chinese herbal medicine', 'proximal hypospadias': 'Tubularized incised plate hypospadias repair', 'prostate cancer': 'radical prostatectomy and iodine 125 interstitial radiotherapy', 'mitomycin - resistant bladder cancer': 'photodynamic therapy in combination with mitomycin C', 'B16 melanoma': 'adenosine triphosphate and treatment with buthionine sulfoximine', 'advanced rectal cancer': 'Nerve - sparing surgery', 'spontaneous pneumothorax': 'Thoracoscopic surgery', 'empyema': 'Thoracoscopy', 'acute cerebral ischemia': 'Antiplatelet therapy', 'renal cell carcinoma': 'Interferon treatment', 'myocardial angiogenesis': 'Gene therapy', 'autoimmune hemolytic anemia': 'heparin', 'epithelial ovarian cancer': 'High - dose chemotherapy with autologous stem - cell support', 'lymphoma': 'Paclitaxel', 'renovascular hypertension': 'Percutaneous transluminal angioplasty', 'moderately symptomatic benign prostatic hyperplasia': 'surgical resection', 'pulmonary hypertension': 'Single or double lung transplantation', 'multiple sclerosis': 'Intravenous immunoglobulin treatment', 'acoustic neuroma': 'Stereotactic radiosurgery', 'cerebral palsy': 'Hyperbaric oxygen therapy', 'postvitrectomy diabetic vitreous hemorrhage': 'Peripheral retinal cryotherapy', 'novel hepatitis B': 'vaccine', 'pertussis': 'vaccines', 'perioperative mortality and myocardial infarction': 'vascular surgery', 'severe secondary peritonitis': 'Surgical management', 'hepatic metastases from colorectal cancer': 'Hepatic arterial infusion of chemotherapy after resection', 'severe diverticular hemorrhage': 'Urgent colonoscopy', 'responsive multiple myeloma': \"` ` Tandem '' high - dose chemoradiotherapy with autologous stem - cell support\"}\n"
     ]
    }
   ],
   "source": [
    "print(med_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26588ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified Disease:  advancedrectalcancer\n",
      "Identified Treatment:  Matrix metalloproteinase inhibitors\n"
     ]
    }
   ],
   "source": [
    "#Predict treatment withthe help of dictionary\n",
    "d=[]\n",
    "disease=''\n",
    "test_sent=[]\n",
    "treatment=''\n",
    "\n",
    "input_sent = 'gangandeep is suffering from advanced rectal cancer'\n",
    "m = spacy.load('en_core_web_sm')\n",
    "doc = m(input_sent)\n",
    "for i in doc:\n",
    "    d.append((i.text,i.pos_,'D'))\n",
    "test_sent.append(sent2features(d))\n",
    "for i,tag in enumerate(crf.predict(test_sent)[0]):\n",
    "    if tag == 'D':\n",
    "        tr = input_sent.split()[i]\n",
    "        disease += tr\n",
    "        if tr in med_dict:\n",
    "            treatment += ''+med_dict.get(tr)\n",
    "if len(treatment) == 0:\n",
    "    treatment='None'\n",
    "print('Identified Disease: ',disease)\n",
    "print('Identified Treatment: ', treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5a339a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
